{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owner/My Drive/Hassan USB Data/Bytewise NLP/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "{'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "example = \"My name is Hafiz Hassan Mustafa and I work at Hugging Face in Brooklyn.\"\n",
    "encoding = tokenizer(example)\n",
    "print(type(encoding))\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.is_fast)\n",
    "print(encoding.is_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BatchEncoding.token_to_chars of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n",
      "<bound method BatchEncoding.token_to_word of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n",
      "<bound method BatchEncoding.token_to_sequence of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n",
      "-----------------------\n",
      "<bound method BatchEncoding.word_to_chars of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n",
      "<bound method BatchEncoding.word_to_tokens of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n",
      "<bound method BatchEncoding.words of {'input_ids': [101, 1422, 1271, 1110, 11679, 8702, 1584, 13583, 21638, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}>\n"
     ]
    }
   ],
   "source": [
    "print(encoding.token_to_chars)\n",
    "print(encoding.token_to_word)\n",
    "print(encoding.token_to_sequence)\n",
    "print(\"-----------------------\")\n",
    "print(encoding.word_to_chars)\n",
    "print(encoding.word_to_tokens)\n",
    "print(encoding.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'My', 'name', 'is', 'Ha', '##fi', '##z', 'Hassan', 'Mustafa', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']\n",
      "[None, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, None]\n"
     ]
    }
   ],
   "source": [
    "print(encoding.tokens())\n",
    "print(encoding.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hafiz'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(3)\n",
    "example[start: end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the base results with the pipeline\n",
    "First, let’s grab a token classification pipeline so we can get some results to compare manually. The model used by default is dbmdz/bert-large-cased-finetuned-conll03-english; it performs NER on sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.token_classification.TokenClassificationPipeline object at 0x1380db640>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99946207,\n",
       "  'index': 4,\n",
       "  'word': 'Ha',\n",
       "  'start': 11,\n",
       "  'end': 13},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9981515,\n",
       "  'index': 5,\n",
       "  'word': '##fi',\n",
       "  'start': 13,\n",
       "  'end': 15},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9992748,\n",
       "  'index': 6,\n",
       "  'word': '##z',\n",
       "  'start': 15,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9994481,\n",
       "  'index': 7,\n",
       "  'word': 'Hassan',\n",
       "  'start': 17,\n",
       "  'end': 23},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9996518,\n",
       "  'index': 8,\n",
       "  'word': 'Mustafa',\n",
       "  'start': 24,\n",
       "  'end': 31},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.97860533,\n",
       "  'index': 13,\n",
       "  'word': 'Hu',\n",
       "  'start': 46,\n",
       "  'end': 48},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.97490025,\n",
       "  'index': 14,\n",
       "  'word': '##gging',\n",
       "  'start': 48,\n",
       "  'end': 53},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.98474944,\n",
       "  'index': 15,\n",
       "  'word': 'Face',\n",
       "  'start': 54,\n",
       "  'end': 58},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9931539,\n",
       "  'index': 17,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 62,\n",
       "  'end': 70}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "print(token_classifier)\n",
    "\n",
    "\n",
    "token_classifier(\"My name is Hafiz Hassan Mustafa and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.token_classification.TokenClassificationPipeline object at 0x13dca7a00>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99919766,\n",
       "  'word': 'Hafiz Hassan Mustafa',\n",
       "  'start': 11,\n",
       "  'end': 31},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9794183,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 46,\n",
       "  'end': 58},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9931539,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 62,\n",
       "  'end': 70}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
    "print(token_classifier)\n",
    "\n",
    "\n",
    "token_classifier(\"My name is Hafiz Hassan Mustafa and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s see how to obtain these results without using the pipeline() function!\n",
    "\n",
    "# From inputs to predictions\n",
    "First we need to tokenize our input and pass it through the model. This is done exactly as in Chapter 2; we instantiate the tokenizer and the model using the AutoXxx classes and then use them on our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "example = \"My name is Hafiz Hassan Mustafa and I work at Hugging Face in Brooklyn.\"\n",
    "inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1422,  1271,  1110, 11679,  8702,  1584, 13583, 21638,  1105,\n",
      "           146,  1250,  1120, 20164, 10932, 10289,  1107,  6010,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "TokenClassifierOutput(loss=None, logits=tensor([[[ 8.6699, -2.3227, -1.4543, -2.1799, -0.5054, -2.1053, -0.2828,\n",
      "          -2.0211,  0.3927],\n",
      "         [ 9.2993, -2.6061, -1.3744, -2.5730,  0.1262, -1.6877,  0.2490,\n",
      "          -2.0817, -0.4864],\n",
      "         [ 9.8000, -2.1779, -0.9389, -2.2924, -0.3021, -1.8406, -0.3051,\n",
      "          -1.8176, -0.0966],\n",
      "         [10.2807, -2.2711, -1.3564, -2.2611, -0.4870, -1.7448, -0.0300,\n",
      "          -1.8164, -0.7071],\n",
      "         [-0.2349, -2.0818, -0.8440, -2.8479,  8.5273, -2.5017, -1.5315,\n",
      "          -2.7283, -0.0501],\n",
      "         [ 0.2101, -2.1174, -0.3184, -2.5794,  7.4289, -2.8034, -1.4155,\n",
      "          -2.6424, -0.5332],\n",
      "         [ 0.0742, -2.1710, -0.8098, -2.8132,  8.3174, -2.7058, -1.3547,\n",
      "          -2.6191, -0.1309],\n",
      "         [-0.4891, -2.0974, -0.6522, -3.1534,  8.5300, -2.6443, -1.0562,\n",
      "          -2.8181,  0.0176],\n",
      "         [-0.3852, -2.2611, -0.7469, -2.8558,  8.8830, -2.4124, -1.4658,\n",
      "          -2.7408, -0.2108],\n",
      "         [ 9.9958, -2.4528, -1.6012, -2.4034, -1.1148, -1.5274,  0.4425,\n",
      "          -1.9307, -0.6502],\n",
      "         [ 9.5831, -2.2237, -1.4945, -2.5056, -0.0617, -1.6702,  0.2471,\n",
      "          -1.8262, -0.6270],\n",
      "         [ 9.7228, -2.2889, -1.4659, -2.8568, -0.2336, -1.7679,  0.8385,\n",
      "          -2.2711, -1.0095],\n",
      "         [ 9.2729, -2.2972, -1.4123, -2.8313, -0.2680, -1.5629,  1.0862,\n",
      "          -2.1463, -0.8733],\n",
      "         [ 2.4578, -3.2521, -1.6664, -3.4095,  1.2846, -1.8483,  6.6307,\n",
      "          -2.9324, -0.2124],\n",
      "         [ 1.8006, -2.5660, -0.1661, -3.2681,  0.2394, -1.3187,  5.9179,\n",
      "          -2.5624, -0.0634],\n",
      "         [ 0.5381, -2.8814,  0.0228, -3.0450,  0.6257, -1.2915,  6.0860,\n",
      "          -2.7068,  0.5644],\n",
      "         [ 9.3256, -2.6840, -1.3346, -2.7025, -0.9867, -1.5510,  1.1588,\n",
      "          -1.9112, -0.3202],\n",
      "         [-0.2825, -2.5081, -1.3357, -2.9945, -0.5514, -2.2102,  1.8690,\n",
      "          -1.6801,  7.1176],\n",
      "         [ 8.6699, -2.3227, -1.4543, -2.1799, -0.5054, -2.1053, -0.2828,\n",
      "          -2.0211,  0.3927],\n",
      "         [ 8.6699, -2.3227, -1.4543, -2.1799, -0.5054, -2.1053, -0.2828,\n",
      "          -2.0211,  0.3927]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we’re using AutoModelForTokenClassification here, we get one set of logits for each token in the input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20, 9])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a batch with 1 sequence of 19 tokens and the model has 9 different labels, so the output of the model has a shape of 1 x 19 x 9. Like for the text classification pipeline, we use a softmax function to convert those logits to probabilities, and we take the argmax to get predictions (note that we can take the argmax on the logits because the softmax does not change the order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
    "predictions = outputs.logits.argmax(dim=-1)[0].tolist()\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.config.id2label attribute contains the mapping of indexes to labels that we can use to make sense of the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw earlier, there are 9 labels: O is the label for the tokens that are not in any named entity (it stands for “outside”), and we then have two labels for each type of entity (miscellaneous, person, organization, and location). The label B-XXX indicates the token is at the beginning of an entity XXX and the label I-XXX indicates the token is inside the entity XXX. For instance, in the current example we would expect our model to classify the token S as B-PER (beginning of a person entity) and the tokens ##yl, ##va and ##in as I-PER (inside a person entity).\n",
    "\n",
    "You might think the model was wrong in this case as it gave the label I-PER to all four of these tokens, but that’s not entirely true. There are actually two formats for those B- and I- labels: IOB1 and IOB2. The IOB2 format (in pink below), is the one we introduced whereas in the IOB1 format (in blue), the labels beginning with B- are only ever used to separate two adjacent entities of the same type. The model we are using was fine-tuned on a dataset using that format, which is why it assigns the label I-PER to the S token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/IOB_versions-dark.svg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/IOB_versions-dark.svg\"\n",
    "Image(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this map, we are ready to reproduce (almost entirely) the results of the first pipeline — we can just grab the score and label of each token that was not classified as O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9994620680809021, 'word': 'Ha'}, {'entity': 'I-PER', 'score': 0.9981513619422913, 'word': '##fi'}, {'entity': 'I-PER', 'score': 0.9992747902870178, 'word': '##z'}, {'entity': 'I-PER', 'score': 0.9994482398033142, 'word': 'Hassan'}, {'entity': 'I-PER', 'score': 0.9996517896652222, 'word': 'Mustafa'}, {'entity': 'I-ORG', 'score': 0.978605329990387, 'word': 'Hu'}, {'entity': 'I-ORG', 'score': 0.9749002456665039, 'word': '##gging'}, {'entity': 'I-ORG', 'score': 0.984749436378479, 'word': 'Face'}, {'entity': 'I-LOC', 'score': 0.9931540489196777, 'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        results.append(\n",
    "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
    "        )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (3, 7),\n",
       " (8, 10),\n",
       " (11, 13),\n",
       " (13, 15),\n",
       " (15, 16),\n",
       " (17, 23),\n",
       " (24, 31),\n",
       " (32, 35),\n",
       " (36, 37),\n",
       " (38, 42),\n",
       " (43, 45),\n",
       " (46, 48),\n",
       " (48, 53),\n",
       " (54, 58),\n",
       " (59, 61),\n",
       " (62, 70),\n",
       " (70, 71),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "inputs_with_offsets[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fi'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[13:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9994620680809021, 'word': 'Ha', 'start': 11, 'end': 13}, {'entity': 'I-PER', 'score': 0.9981513619422913, 'word': '##fi', 'start': 13, 'end': 15}, {'entity': 'I-PER', 'score': 0.9992747902870178, 'word': '##z', 'start': 15, 'end': 16}, {'entity': 'I-PER', 'score': 0.9994482398033142, 'word': 'Hassan', 'start': 17, 'end': 23}, {'entity': 'I-PER', 'score': 0.9996517896652222, 'word': 'Mustafa', 'start': 24, 'end': 31}, {'entity': 'I-ORG', 'score': 0.978605329990387, 'word': 'Hu', 'start': 46, 'end': 48}, {'entity': 'I-ORG', 'score': 0.9749002456665039, 'word': '##gging', 'start': 48, 'end': 53}, {'entity': 'I-ORG', 'score': 0.984749436378479, 'word': 'Face', 'start': 54, 'end': 58}, {'entity': 'I-LOC', 'score': 0.9931540489196777, 'word': 'Brooklyn', 'start': 62, 'end': 70}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        start, end = offsets[idx]\n",
    "        results.append(\n",
    "            {\n",
    "                \"entity\": label,\n",
    "                \"score\": probabilities[idx][pred],\n",
    "                \"word\": tokens[idx],\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[46:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9991976499557496, 'word': 'Hafiz Hassan Mustafa', 'start': 11, 'end': 31}, {'entity_group': 'ORG', 'score': 0.9794183373451233, 'word': 'Hugging Face', 'start': 46, 'end': 58}, {'entity_group': 'LOC', 'score': 0.9931540489196777, 'word': 'Brooklyn', 'start': 62, 'end': 70}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        # Remove the B- or I-\n",
    "        label = label[2:]\n",
    "        start, _ = offsets[idx]\n",
    "\n",
    "        # Grab all the tokens labeled with I-label\n",
    "        all_scores = []\n",
    "        while (\n",
    "            idx < len(predictions)\n",
    "            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
    "        ):\n",
    "            all_scores.append(probabilities[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "\n",
    "        # The score is the mean of all the scores of the tokens in that grouped entity\n",
    "        score = np.mean(all_scores).item()\n",
    "        word = example[start:end]\n",
    "        results.append(\n",
    "            {\n",
    "                \"entity_group\": label,\n",
    "                \"score\": score,\n",
    "                \"word\": word,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "            }\n",
    "        )\n",
    "    idx += 1\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9991976499557496,\n",
       "  'word': 'Hafiz Hassan Mustafa',\n",
       "  'start': 11,\n",
       "  'end': 31},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9794183373451233,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 46,\n",
       "  'end': 58},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9931540489196777,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 62,\n",
       "  'end': 70}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
