{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX + ONNX Runtime\n",
    "Before you begin, make sure you have all the necessary libraries installed :\n",
    "\n",
    "- pip install optimum[exporters]\n",
    "- pip install onnxruntime==1.16\n",
    "\n",
    "It is possible to export ðŸ¤— Transformers and Diffusers models to the ONNX format and perform graph optimization as well as quantization easily:\n",
    "- optimum-cli export onnx -m deepset/roberta-base-squad2 --optimize O2 roberta_base_qa_onnx\n",
    "\n",
    "The model can then be quantized using onnxruntime:\n",
    "- optimum-cli onnxruntime quantize \\\n",
    "  --avx512 \\\n",
    "  --onnx_model roberta_base_qa_onnx \\\n",
    "  -o quantized_roberta_base_qa_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaTokenizerFast(name_or_path='deepset/roberta-base-squad2', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"deepset/roberta-base-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta_base_qa_onnx/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ORTModelForQuestionAnswering.from_pretrained(\"roberta_base_qa_onnx\")\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized_model\n",
      "[RobertaTokenizerFast(name_or_path='roberta_base_qa_onnx', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}, RobertaTokenizerFast(name_or_path='roberta_base_qa_onnx', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(model.base_model_prefix)\n",
    "print(model.preprocessors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.question_answering.QuestionAnsweringPipeline object at 0x14a5cbaf0>\n"
     ]
    }
   ],
   "source": [
    "qa_pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "print(qa_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.532249927520752,\n",
       " 'start': 11,\n",
       " 'end': 29,\n",
       " 'answer': 'an awesome library'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What's Optimum?\"\n",
    "context = \"Optimum is an awesome library everyone should use!\"\n",
    "results = qa_pipe(question=question, context=context)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Model Precision Before Quantization:\n",
    "- Before quantizing the model, the precision of the weights is typically in fp32 (32-bit floating point). This is the default precision for most models unless you explicitly convert or quantize them to a different format.\n",
    "\n",
    "# Check the Quantized Model's Precision:\n",
    "- To verify that your model has been quantized to int8, you can inspect the ONNX model's nodes to see if the operations are using int8 tensors. You can do this by loading the ONNX model and examining the data types of its nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor 'attention_mask' of node '' has data type: int64\n",
      "Input tensor 'input_ids' of node '/roberta/embeddings/Equal' has data type: int64\n",
      "Input tensor 'input_ids' of node '/roberta/Shape_1' has data type: int64\n",
      "Input tensor 'input_ids' of node '/roberta/embeddings/word_embeddings/Gather' has data type: int64\n",
      "Output tensor 'start_logits' of node '/Squeeze' has data type: float32\n",
      "Output tensor 'end_logits' of node '/Squeeze_1' has data type: float32\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"quantized_roberta_base_qa_onnx/model_quantized.onnx\")\n",
    "\n",
    "# Iterate through the model's nodes\n",
    "for node in onnx_model.graph.node:\n",
    "    for input_tensor in node.input:\n",
    "        input_info = next((i for i in onnx_model.graph.input if i.name == input_tensor), None)\n",
    "        if input_info:\n",
    "            data_type = input_info.type.tensor_type.elem_type\n",
    "            print(f\"Input tensor '{input_tensor}' of node '{node.name}' has data type: {onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[data_type]}\")\n",
    "\n",
    "    for output_tensor in node.output:\n",
    "        output_info = next((o for o in onnx_model.graph.output if o.name == output_tensor), None)\n",
    "        if output_info:\n",
    "            data_type = output_info.type.tensor_type.elem_type\n",
    "            print(f\"Output tensor '{output_tensor}' of node '{node.name}' has data type: {onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[data_type]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Size: 496.27695 MB\n",
      "Quantized Model Size: 124.539271 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check the size of the original ONNX model\n",
    "original_model_size = os.path.getsize(\"roberta_base_qa_onnx/model.onnx\")\n",
    "print(f\"Original Model Size: {original_model_size / 1e6} MB\")\n",
    "\n",
    "# Check the size of the quantized ONNX model\n",
    "quantized_model_size = os.path.getsize(\"quantized_roberta_base_qa_onnx/model_quantized.onnx\")\n",
    "print(f\"Quantized Model Size: {quantized_model_size / 1e6} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: , OpType: Cast\n",
      "  Input tensor 'attention_mask' has data type: int64\n",
      "Node: /roberta/embeddings/Equal, OpType: Equal\n",
      "  Input tensor 'input_ids' has data type: int64\n",
      "Node: /roberta/Shape_1, OpType: Shape\n",
      "  Input tensor 'input_ids' has data type: int64\n",
      "Node: /roberta/embeddings/word_embeddings/Gather, OpType: Gather\n",
      "  Input tensor 'input_ids' has data type: int64\n",
      "Node: MaskReduceSum_0, OpType: ReduceSum\n",
      "Node: /roberta/embeddings/Not, OpType: Not\n",
      "Node: /roberta/Gather_1, OpType: Gather\n",
      "Node: /roberta/Reshape, OpType: Reshape\n",
      "Node: /roberta/embeddings/word_embeddings/Gather_output_0_DequantizeLinear, OpType: DequantizeLinear\n",
      "Node: /roberta/embeddings/Cast, OpType: Cast\n",
      "Node: /roberta/Unsqueeze_2, OpType: Unsqueeze\n",
      "Node: /roberta/Equal, OpType: Equal\n",
      "Node: /roberta/embeddings/CumSum, OpType: CumSum\n",
      "Node: /roberta/Slice, OpType: Slice\n",
      "Node: /roberta/Where, OpType: Where\n",
      "Node: /roberta/embeddings/Mul, OpType: Mul\n",
      "Node: /roberta/Expand, OpType: Expand\n",
      "Node: /roberta/embeddings/Cast_1, OpType: Cast\n",
      "Node: /roberta/embeddings/token_type_embeddings/Gather, OpType: Gather\n",
      "Node: /roberta/embeddings/Add, OpType: Add\n",
      "Node: /roberta/embeddings/token_type_embeddings/Gather_output_0_DequantizeLinear, OpType: DequantizeLinear\n",
      "Node: /roberta/embeddings/position_embeddings/Gather, OpType: Gather\n",
      "Node: /roberta/embeddings/Add_1, OpType: Add\n",
      "Node: /roberta/embeddings/position_embeddings/Gather_output_0_DequantizeLinear, OpType: DequantizeLinear\n",
      "Node: /roberta/embeddings/Add_2, OpType: Add\n",
      "Node: /roberta/embeddings/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/embeddings/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_0_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.0/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.0/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.0/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.0/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.0/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.0/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.0/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.0/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.0/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.0/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.0/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.0/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.0/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.0/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.0/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.0/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.0/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.0/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.0/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.0/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.0/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_1_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.1/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.1/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.1/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.1/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.1/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.1/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.1/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.1/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.1/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.1/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.1/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.1/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.1/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_11, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.1/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.1/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.1/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.1/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.1/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.1/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.1/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.1/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_2_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.2/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.2/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.2/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.2/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.2/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.2/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.2/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.2/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.2/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.2/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.2/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.2/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.2/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_12, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.2/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.2/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.2/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.2/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.2/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.2/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.2/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.2/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_3_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.3/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.3/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.3/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.3/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.3/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.3/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.3/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.3/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.3/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.3/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.3/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.3/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.3/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_13, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.3/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.3/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.3/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.3/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.3/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.3/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.3/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.3/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_4_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.4/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.4/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.4/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.4/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.4/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.4/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.4/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.4/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.4/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.4/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.4/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.4/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.4/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_14, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.4/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.4/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.4/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.4/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.4/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.4/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.4/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.4/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_5_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.5/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.5/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.5/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.5/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.5/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.5/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.5/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.5/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.5/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.5/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.5/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.5/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.5/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_15, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.5/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.5/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.5/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.5/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.5/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.5/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.5/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.5/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_6_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.6/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.6/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.6/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.6/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.6/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.6/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.6/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.6/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.6/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.6/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.6/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.6/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.6/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_16, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.6/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.6/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.6/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.6/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.6/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.6/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.6/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.6/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_7_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.7/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.7/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.7/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.7/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.7/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.7/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.7/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.7/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.7/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.7/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.7/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.7/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.7/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_17, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.7/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.7/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.7/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.7/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.7/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.7/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.7/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.7/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_8_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.8/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.8/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.8/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.8/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.8/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.8/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.8/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.8/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.8/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.8/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.8/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.8/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.8/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_18, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.8/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.8/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.8/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.8/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.8/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.8/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.8/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.8/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_9_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.9/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.9/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.9/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.9/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.9/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.9/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.9/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.9/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.9/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.9/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.9/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.9/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.9/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_19, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.9/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.9/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.9/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.9/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.9/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.9/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.9/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.9/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_10_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.10/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.10/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.10/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.10/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.10/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.10/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.10/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.10/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.10/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.10/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.10/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.10/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.10/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_20, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.10/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.10/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.10/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.10/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.10/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.10/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.10/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.10/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: Attention_11_quant, OpType: QAttention\n",
      "Node: /roberta/encoder/layer.11/attention/self/Reshape_3_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.11/attention/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.11/attention/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.11/attention/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.11/attention/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.11/attention/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.11/attention/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.11/attention/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.11/attention/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.11/intermediate/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.11/intermediate/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.11/intermediate/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.11/intermediate/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: BiasGelu_token_21, OpType: BiasGelu\n",
      "Node: /roberta/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /roberta/encoder/layer.11/output/dense/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.11/output/dense/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /roberta/encoder/layer.11/output/dense/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /roberta/encoder/layer.11/output/dense/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /roberta/encoder/layer.11/output/dense/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.11/output/Add, OpType: Add\n",
      "Node: /roberta/encoder/layer.11/output/LayerNorm/Mul/LayerNormFusion/, OpType: LayerNormalization\n",
      "Node: /roberta/encoder/layer.11/output/LayerNorm/Add_1_output_0_QuantizeLinear, OpType: DynamicQuantizeLinear\n",
      "Node: /qa_outputs/MatMul_quant_scales_mul, OpType: Mul\n",
      "Node: /qa_outputs/MatMul_quant, OpType: MatMulInteger\n",
      "Node: /qa_outputs/MatMul_output_0_output_quantized_cast, OpType: Cast\n",
      "Node: /qa_outputs/MatMul_quant_output_scale_mul, OpType: Mul\n",
      "Node: /qa_outputs/Add, OpType: Add\n",
      "Node: /Split, OpType: Split\n",
      "Node: /Squeeze, OpType: Squeeze\n",
      "  Output tensor 'start_logits' has data type: float32\n",
      "Node: /Squeeze_1, OpType: Squeeze\n",
      "  Output tensor 'end_logits' has data type: float32\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"quantized_roberta_base_qa_onnx/model_quantized.onnx\")\n",
    "\n",
    "# Iterate through the model's nodes\n",
    "for node in onnx_model.graph.node:\n",
    "    print(f\"Node: {node.name}, OpType: {node.op_type}\")\n",
    "    for input_tensor in node.input:\n",
    "        input_info = next((i for i in onnx_model.graph.input if i.name == input_tensor), None)\n",
    "        if input_info:\n",
    "            data_type = input_info.type.tensor_type.elem_type\n",
    "            print(f\"  Input tensor '{input_tensor}' has data type: {onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[data_type]}\")\n",
    "\n",
    "    for output_tensor in node.output:\n",
    "        output_info = next((o for o in onnx_model.graph.output if o.name == output_tensor), None)\n",
    "        if output_info:\n",
    "            data_type = output_info.type.tensor_type.elem_type\n",
    "            print(f\"  Output tensor '{output_tensor}' has data type: {onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[data_type]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
